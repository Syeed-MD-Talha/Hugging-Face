{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec datasets pandas"
      ],
      "metadata": {
        "id": "T0xQOOZ-DFbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import sys"
      ],
      "metadata": {
        "id": "OfKvKwoACi-1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading GLUE MRPC dataset...\")\n",
        "# Load the dataset\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtnLoZbPHkLV",
        "outputId": "83fbe407-2e72-4801-96db-96bf2697fb95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GLUE MRPC dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(f\"Dataset structure: {raw_datasets}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj0Fg1jb_TDF",
        "outputId": "8af6645f-4c41-4d08-d9af-648fc8a581cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded successfully!\n",
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available splits:\")\n",
        "for split_name, split_data in raw_datasets.items():\n",
        "    print(f\"  - {split_name}: {len(split_data)} examples\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG3QvOp1_TAd",
        "outputId": "29231561-c37f-4c0e-e509-22e212016171"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available splits:\n",
            "  - train: 3668 examples\n",
            "  - validation: 408 examples\n",
            "  - test: 1725 examples\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the training data\n",
        "train_data = raw_datasets['train']\n",
        "print(\"Training data info:\")\n",
        "print(f\"  - Number of examples: {len(train_data)}\")\n",
        "print(f\"  - Features: {train_data.features}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLQSorfb_S9l",
        "outputId": "8e001f6d-4772-4402-8216-60ee84c70dfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data info:\n",
            "  - Number of examples: 3668\n",
            "  - Features: {'sentence1': Value('string'), 'sentence2': Value('string'), 'label': ClassLabel(names=['not_equivalent', 'equivalent']), 'idx': Value('int32')}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first few examples\n",
        "print(\"First 3 examples from training set:\")\n",
        "for i in range(min(5, len(train_data))):\n",
        "    example = train_data[i]\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    for key, value in example.items():\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yqf9GeXAGM0",
        "outputId": "1f429b1c-8673-4cb0-813e-2f1887508b6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 examples from training set:\n",
            "\n",
            "Example 1:\n",
            "  sentence1: Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n",
            "  sentence2: Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
            "  label: 1\n",
            "  idx: 0\n",
            "\n",
            "Example 2:\n",
            "  sentence1: Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\n",
            "  sentence2: Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n",
            "  label: 0\n",
            "  idx: 1\n",
            "\n",
            "Example 3:\n",
            "  sentence1: They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\n",
            "  sentence2: On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n",
            "  label: 1\n",
            "  idx: 2\n",
            "\n",
            "Example 4:\n",
            "  sentence1: Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .\n",
            "  sentence2: Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .\n",
            "  label: 0\n",
            "  idx: 3\n",
            "\n",
            "Example 5:\n",
            "  sentence1: The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .\n",
            "  sentence2: PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .\n",
            "  label: 1\n",
            "  idx: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Convert to pandas for easier exploration\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Converting to pandas DataFrame for easier exploration...\")\n",
        "\n",
        "train_df = pd.DataFrame(train_data)\n",
        "print(f\"\\nDataFrame shape: {train_df.shape}\")\n",
        "print(f\"Columns: {list(train_df.columns)}\")\n",
        "\n",
        "# Show basic statistics\n",
        "print(\"\\nDataset statistics:\")\n",
        "print(train_df.describe())\n",
        "\n",
        "# Show label distribution\n",
        "if 'label' in train_df.columns:\n",
        "    print(\"\\nLabel distribution:\")\n",
        "    print(train_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMC-N7ZEAGKV",
        "outputId": "2b6fdc76-f8a6-4881-d0a3-c2d02e29f0c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Converting to pandas DataFrame for easier exploration...\n",
            "\n",
            "DataFrame shape: (3668, 4)\n",
            "Columns: ['sentence1', 'sentence2', 'label', 'idx']\n",
            "\n",
            "Dataset statistics:\n",
            "             label          idx\n",
            "count  3668.000000  3668.000000\n",
            "mean      0.674482  2039.858233\n",
            "std       0.468632  1176.050149\n",
            "min       0.000000     0.000000\n",
            "25%       0.000000  1022.750000\n",
            "50%       1.000000  2039.500000\n",
            "75%       1.000000  3054.250000\n",
            "max       1.000000  4075.000000\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "1    2474\n",
            "0    1194\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample data\n",
        "print(\"\\nSample data (first 5 rows):\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfGZNL-dAGH1",
        "outputId": "ab202796-cd44-43df-e17f-f08b55adf7de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample data (first 5 rows):\n",
            "                                           sentence1  \\\n",
            "0  Amrozi accused his brother , whom he called \" ...   \n",
            "1  Yucaipa owned Dominick 's before selling the c...   \n",
            "2  They had published an advertisement on the Int...   \n",
            "3  Around 0335 GMT , Tab shares were up 19 cents ...   \n",
            "4  The stock rose $ 2.11 , or about 11 percent , ...   \n",
            "\n",
            "                                           sentence2  label  idx  \n",
            "0  Referring to him as only \" the witness \" , Amr...      1    0  \n",
            "1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0    1  \n",
            "2  On June 10 , the ship 's owners had published ...      1    2  \n",
            "3  Tab shares jumped 20 cents , or 4.6 % , to set...      0    3  \n",
            "4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1    4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first few examples\n",
        "print(\"First 3 examples from training set:\")\n",
        "for i in range(min(5, len(raw_datasets['test']))):\n",
        "    example = train_data[i]\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    for key, value in example.items():\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc8B7yldAGE2",
        "outputId": "3de0132a-021d-40e6-fc0e-414ca937859f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 examples from training set:\n",
            "\n",
            "Example 1:\n",
            "  sentence1: Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n",
            "  sentence2: Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
            "  label: 1\n",
            "  idx: 0\n",
            "\n",
            "Example 2:\n",
            "  sentence1: Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\n",
            "  sentence2: Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n",
            "  label: 0\n",
            "  idx: 1\n",
            "\n",
            "Example 3:\n",
            "  sentence1: They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\n",
            "  sentence2: On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n",
            "  label: 1\n",
            "  idx: 2\n",
            "\n",
            "Example 4:\n",
            "  sentence1: Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .\n",
            "  sentence2: Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .\n",
            "  label: 0\n",
            "  idx: 3\n",
            "\n",
            "Example 5:\n",
            "  sentence1: The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .\n",
            "  sentence2: PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .\n",
            "  label: 1\n",
            "  idx: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "# Run this in your terminal or notebook:\n",
        "# pip install datasets pandas\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import sys\n",
        "\n",
        "def load_and_explore_dataset():\n",
        "    \"\"\"Load and explore a Hugging Face dataset with error handling\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\"Loading GLUE MRPC dataset...\")\n",
        "        # Load the dataset\n",
        "        raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "        print(\"✅ Dataset loaded successfully!\")\n",
        "        print(f\"Dataset structure: {raw_datasets}\")\n",
        "        print()\n",
        "\n",
        "        # Explore the dataset splits\n",
        "        print(\"Available splits:\")\n",
        "        for split_name, split_data in raw_datasets.items():\n",
        "            print(f\"  - {split_name}: {len(split_data)} examples\")\n",
        "        print()\n",
        "\n",
        "        # Look at the training data\n",
        "        train_data = raw_datasets['train']\n",
        "        print(\"Training data info:\")\n",
        "        print(f\"  - Number of examples: {len(train_data)}\")\n",
        "        print(f\"  - Features: {train_data.features}\")\n",
        "        print()\n",
        "\n",
        "        # Show first few examples\n",
        "        print(\"First 3 examples from training set:\")\n",
        "        for i in range(min(3, len(train_data))):\n",
        "            example = train_data[i]\n",
        "            print(f\"\\nExample {i+1}:\")\n",
        "            for key, value in example.items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        # Convert to pandas for easier exploration\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Converting to pandas DataFrame for easier exploration...\")\n",
        "\n",
        "        train_df = pd.DataFrame(train_data)\n",
        "        print(f\"\\nDataFrame shape: {train_df.shape}\")\n",
        "        print(f\"Columns: {list(train_df.columns)}\")\n",
        "\n",
        "        # Show basic statistics\n",
        "        print(\"\\nDataset statistics:\")\n",
        "        print(train_df.describe())\n",
        "\n",
        "        # Show label distribution\n",
        "        if 'label' in train_df.columns:\n",
        "            print(\"\\nLabel distribution:\")\n",
        "            print(train_df['label'].value_counts())\n",
        "\n",
        "        # Show sample data\n",
        "        print(\"\\nSample data (first 5 rows):\")\n",
        "        print(train_df.head())\n",
        "\n",
        "        return raw_datasets, train_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading dataset: {e}\")\n",
        "        print(f\"Error type: {type(e).__name__}\")\n",
        "\n",
        "        # Common troubleshooting steps\n",
        "        print(\"\\n🔧 Troubleshooting steps:\")\n",
        "        print(\"1. Make sure you have internet connection\")\n",
        "        print(\"2. Try updating the datasets library: pip install --upgrade datasets\")\n",
        "        print(\"3. Check if the dataset name is correct\")\n",
        "        print(\"4. Try a different dataset first, like: load_dataset('imdb')\")\n",
        "\n",
        "        return None, None\n",
        "\n",
        "def try_alternative_datasets():\n",
        "    \"\"\"Try loading some popular alternative datasets\"\"\"\n",
        "\n",
        "    alternative_datasets = [\n",
        "        (\"imdb\", None),  # Movie reviews\n",
        "        (\"squad\", None),  # Question answering\n",
        "        (\"wikitext\", \"wikitext-2-raw-v1\"),  # Text corpus\n",
        "    ]\n",
        "\n",
        "    print(\"Trying alternative datasets...\")\n",
        "\n",
        "    for dataset_name, config in alternative_datasets:\n",
        "        try:\n",
        "            print(f\"\\nTrying {dataset_name}...\")\n",
        "            if config:\n",
        "                dataset = load_dataset(dataset_name, config)\n",
        "            else:\n",
        "                dataset = load_dataset(dataset_name)\n",
        "\n",
        "            print(f\"✅ {dataset_name} loaded successfully!\")\n",
        "            print(f\"Structure: {dataset}\")\n",
        "\n",
        "            # Show first example\n",
        "            first_split = list(dataset.keys())[0]\n",
        "            first_example = dataset[first_split][0]\n",
        "            print(f\"First example: {first_example}\")\n",
        "\n",
        "            return dataset\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {dataset_name}: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Hugging Face Dataset Loader\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Try to load the original dataset\n",
        "    raw_datasets, train_df = load_and_explore_dataset()\n",
        "\n",
        "    # If that fails, try alternatives\n",
        "    if raw_datasets is None:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Trying alternative datasets...\")\n",
        "        alternative_dataset = try_alternative_datasets()\n",
        "\n",
        "    print(\"\\n🎉 Dataset exploration complete!\")\n",
        "    print(\"\\nNext steps you can try:\")\n",
        "    print(\"- Access specific examples: raw_datasets['train'][0]\")\n",
        "    print(\"- Convert to pandas: pd.DataFrame(raw_datasets['train'])\")\n",
        "    print(\"- Explore features: raw_datasets['train'].features\")\n",
        "    print(\"- Filter data: raw_datasets['train'].filter(lambda x: x['label'] == 1)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qzq99Lng_TFl",
        "outputId": "e2e21ffb-4d39-4a0d-f5a0-1e38be563d0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face Dataset Loader\n",
            "========================================\n",
            "Loading GLUE MRPC dataset...\n",
            "✅ Dataset loaded successfully!\n",
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n",
            "\n",
            "Available splits:\n",
            "  - train: 3668 examples\n",
            "  - validation: 408 examples\n",
            "  - test: 1725 examples\n",
            "\n",
            "Training data info:\n",
            "  - Number of examples: 3668\n",
            "  - Features: {'sentence1': Value('string'), 'sentence2': Value('string'), 'label': ClassLabel(names=['not_equivalent', 'equivalent']), 'idx': Value('int32')}\n",
            "\n",
            "First 3 examples from training set:\n",
            "\n",
            "Example 1:\n",
            "  sentence1: Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n",
            "  sentence2: Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
            "  label: 1\n",
            "  idx: 0\n",
            "\n",
            "Example 2:\n",
            "  sentence1: Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\n",
            "  sentence2: Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n",
            "  label: 0\n",
            "  idx: 1\n",
            "\n",
            "Example 3:\n",
            "  sentence1: They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\n",
            "  sentence2: On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n",
            "  label: 1\n",
            "  idx: 2\n",
            "\n",
            "==================================================\n",
            "Converting to pandas DataFrame for easier exploration...\n",
            "\n",
            "DataFrame shape: (3668, 4)\n",
            "Columns: ['sentence1', 'sentence2', 'label', 'idx']\n",
            "\n",
            "Dataset statistics:\n",
            "             label          idx\n",
            "count  3668.000000  3668.000000\n",
            "mean      0.674482  2039.858233\n",
            "std       0.468632  1176.050149\n",
            "min       0.000000     0.000000\n",
            "25%       0.000000  1022.750000\n",
            "50%       1.000000  2039.500000\n",
            "75%       1.000000  3054.250000\n",
            "max       1.000000  4075.000000\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "1    2474\n",
            "0    1194\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample data (first 5 rows):\n",
            "                                           sentence1  \\\n",
            "0  Amrozi accused his brother , whom he called \" ...   \n",
            "1  Yucaipa owned Dominick 's before selling the c...   \n",
            "2  They had published an advertisement on the Int...   \n",
            "3  Around 0335 GMT , Tab shares were up 19 cents ...   \n",
            "4  The stock rose $ 2.11 , or about 11 percent , ...   \n",
            "\n",
            "                                           sentence2  label  idx  \n",
            "0  Referring to him as only \" the witness \" , Amr...      1    0  \n",
            "1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0    1  \n",
            "2  On June 10 , the ship 's owners had published ...      1    2  \n",
            "3  Tab shares jumped 20 cents , or 4.6 % , to set...      0    3  \n",
            "4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1    4  \n",
            "\n",
            "🎉 Dataset exploration complete!\n",
            "\n",
            "Next steps you can try:\n",
            "- Access specific examples: raw_datasets['train'][0]\n",
            "- Convert to pandas: pd.DataFrame(raw_datasets['train'])\n",
            "- Explore features: raw_datasets['train'].features\n",
            "- Filter data: raw_datasets['train'].filter(lambda x: x['label'] == 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing metadata.widgets for Github"
      ],
      "metadata": {
        "id": "XnfHTEq3GgKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix for Jupyter Notebook Widget Metadata Error\n",
        "# \"the 'state' key is missing from 'metadata.widgets'\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def fix_notebook_widgets(notebook_path):\n",
        "    \"\"\"\n",
        "    Fix notebook widget metadata by removing or fixing widget state\n",
        "\n",
        "    Args:\n",
        "        notebook_path (str): Path to the .ipynb file\n",
        "    \"\"\"\n",
        "\n",
        "    # Make a backup first\n",
        "    backup_path = notebook_path.replace('.ipynb', '_backup.ipynb')\n",
        "    shutil.copy2(notebook_path, backup_path)\n",
        "    print(f\"✅ Backup created: {backup_path}\")\n",
        "\n",
        "    try:\n",
        "        # Read the notebook\n",
        "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "            notebook = json.load(f)\n",
        "\n",
        "        print(f\"📖 Loaded notebook: {notebook_path}\")\n",
        "\n",
        "        # Check if widgets metadata exists\n",
        "        if 'metadata' in notebook and 'widgets' in notebook['metadata']:\n",
        "            print(\"🔍 Found widget metadata, checking structure...\")\n",
        "\n",
        "            widgets = notebook['metadata']['widgets']\n",
        "\n",
        "            # Method 1: Add missing 'state' key\n",
        "            if isinstance(widgets, dict) and 'state' not in widgets:\n",
        "                print(\"🔧 Adding missing 'state' key...\")\n",
        "                widgets['state'] = {}\n",
        "\n",
        "            # Method 2: If widgets is malformed, replace with proper structure\n",
        "            elif not isinstance(widgets, dict):\n",
        "                print(\"🔧 Fixing malformed widgets structure...\")\n",
        "                notebook['metadata']['widgets'] = {\n",
        "                    \"application/vnd.jupyter.widget-state+json\": {\n",
        "                        \"state\": {},\n",
        "                        \"version_major\": 2,\n",
        "                        \"version_minor\": 0\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            # Method 3: Ensure proper widget structure\n",
        "            else:\n",
        "                print(\"🔧 Ensuring proper widget structure...\")\n",
        "                if 'application/vnd.jupyter.widget-state+json' not in widgets:\n",
        "                    notebook['metadata']['widgets'] = {\n",
        "                        \"application/vnd.jupyter.widget-state+json\": {\n",
        "                            \"state\": widgets.get('state', {}),\n",
        "                            \"version_major\": 2,\n",
        "                            \"version_minor\": 0\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "        # Clean up cell metadata widgets as well\n",
        "        if 'cells' in notebook:\n",
        "            for cell in notebook['cells']:\n",
        "                if 'metadata' in cell and 'widgets' in cell['metadata']:\n",
        "                    print(\"🔧 Cleaning cell widget metadata...\")\n",
        "                    # Remove problematic cell-level widget metadata\n",
        "                    del cell['metadata']['widgets']\n",
        "\n",
        "        # Write the fixed notebook\n",
        "        with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(notebook, f, indent=2)\n",
        "\n",
        "        print(\"✅ Notebook fixed successfully!\")\n",
        "        print(f\"📁 Original saved as: {backup_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error fixing notebook: {e}\")\n",
        "        # Restore backup if something went wrong\n",
        "        shutil.copy2(backup_path, notebook_path)\n",
        "        print(\"🔄 Backup restored due to error\")\n",
        "\n",
        "def remove_all_widgets(notebook_path):\n",
        "    \"\"\"\n",
        "    Alternative solution: Remove all widget metadata completely\n",
        "\n",
        "    Args:\n",
        "        notebook_path (str): Path to the .ipynb file\n",
        "    \"\"\"\n",
        "\n",
        "    # Make a backup first\n",
        "    backup_path = notebook_path.replace('.ipynb', '_backup_no_widgets.ipynb')\n",
        "    shutil.copy2(notebook_path, backup_path)\n",
        "    print(f\"✅ Backup created: {backup_path}\")\n",
        "\n",
        "    try:\n",
        "        # Read the notebook\n",
        "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "            notebook = json.load(f)\n",
        "\n",
        "        print(f\"📖 Loaded notebook: {notebook_path}\")\n",
        "\n",
        "        # Remove widgets from main metadata\n",
        "        if 'metadata' in notebook and 'widgets' in notebook['metadata']:\n",
        "            print(\"🗑️ Removing main widget metadata...\")\n",
        "            del notebook['metadata']['widgets']\n",
        "\n",
        "        # Remove widgets from cell metadata\n",
        "        if 'cells' in notebook:\n",
        "            for cell in notebook['cells']:\n",
        "                if 'metadata' in cell and 'widgets' in cell['metadata']:\n",
        "                    print(\"🗑️ Removing cell widget metadata...\")\n",
        "                    del cell['metadata']['widgets']\n",
        "\n",
        "        # Write the cleaned notebook\n",
        "        with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(notebook, f, indent=2)\n",
        "\n",
        "        print(\"✅ All widgets removed successfully!\")\n",
        "        print(f\"📁 Original saved as: {backup_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error removing widgets: {e}\")\n",
        "        # Restore backup if something went wrong\n",
        "        shutil.copy2(backup_path, notebook_path)\n",
        "        print(\"🔄 Backup restored due to error\")\n",
        "\n",
        "def batch_fix_notebooks(directory_path):\n",
        "    \"\"\"\n",
        "    Fix all notebooks in a directory\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Path to directory containing .ipynb files\n",
        "    \"\"\"\n",
        "\n",
        "    directory = Path(directory_path)\n",
        "    notebook_files = list(directory.glob('*.ipynb'))\n",
        "\n",
        "    if not notebook_files:\n",
        "        print(\"❌ No notebook files found in directory\")\n",
        "        return\n",
        "\n",
        "    print(f\"🔍 Found {len(notebook_files)} notebook files\")\n",
        "\n",
        "    for notebook_file in notebook_files:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing: {notebook_file.name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            fix_notebook_widgets(str(notebook_file))\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to fix {notebook_file.name}: {e}\")\n",
        "\n",
        "# ============================================\n",
        "# Command-line style usage instructions\n",
        "# ============================================\n",
        "\n",
        "def print_usage_instructions():\n",
        "    \"\"\"Print instructions for using the fix\"\"\"\n",
        "\n",
        "    print(\"🚀 HOW TO USE THIS FIX:\")\n",
        "    print(\"=\" * 50)\n",
        "    print()\n",
        "    print(\"METHOD 1: Fix a single notebook\")\n",
        "    print(\"fix_notebook_widgets('your_notebook.ipynb')\")\n",
        "    print()\n",
        "    print(\"METHOD 2: Remove all widgets (safer)\")\n",
        "    print(\"remove_all_widgets('your_notebook.ipynb')\")\n",
        "    print()\n",
        "    print(\"METHOD 3: Fix all notebooks in a directory\")\n",
        "    print(\"batch_fix_notebooks('/path/to/your/notebooks')\")\n",
        "    print()\n",
        "    print(\"🔧 MANUAL ALTERNATIVE:\")\n",
        "    print(\"1. Open your notebook in Jupyter\")\n",
        "    print(\"2. Go to Kernel -> Restart & Clear Output\")\n",
        "    print(\"3. Save the notebook\")\n",
        "    print(\"4. This removes all widget states\")\n",
        "    print()\n",
        "    print(\"💡 PREVENTION TIPS:\")\n",
        "    print(\"- Always clear output before committing: Cell -> All Output -> Clear\")\n",
        "    print(\"- Use 'Restart & Clear Output' before saving\")\n",
        "    print(\"- Add .ipynb_checkpoints/ to .gitignore\")\n",
        "    print()\n",
        "    print(\"🐙 GITHUB SPECIFIC:\")\n",
        "    print(\"- GitHub renders notebooks better without widget metadata\")\n",
        "    print(\"- Consider using nbstripout: pip install nbstripout\")\n",
        "    print(\"- Add git filter: nbstripout --install\")\n",
        "\n",
        "# ============================================\n",
        "# Quick fix function for immediate use\n",
        "# ============================================\n",
        "\n",
        "def quick_fix(notebook_path):\n",
        "    \"\"\"Quick one-liner fix for immediate use\"\"\"\n",
        "\n",
        "    print(f\"🚀 Quick fixing: {notebook_path}\")\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(notebook_path):\n",
        "        print(f\"❌ File not found: {notebook_path}\")\n",
        "        return\n",
        "\n",
        "    # Try the safer approach first (remove widgets)\n",
        "    try:\n",
        "        remove_all_widgets(notebook_path)\n",
        "        print(\"✅ Quick fix completed!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Quick fix failed: {e}\")\n",
        "        print(\"Try the manual method or check the file path\")\n",
        "\n",
        "# ============================================\n",
        "# Example usage\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Jupyter Notebook Widget Metadata Fixer\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Print usage instructions\n",
        "    print_usage_instructions()\n",
        "\n",
        "    # Example - replace with your actual notebook path\n",
        "    example_notebook = \"your_notebook.ipynb\"\n",
        "\n",
        "    print(f\"\\n🎯 TO FIX YOUR NOTEBOOK:\")\n",
        "    print(f\"quick_fix('{example_notebook}')\")\n",
        "    print(f\"# OR\")\n",
        "    print(f\"remove_all_widgets('{example_notebook}')\")\n",
        "\n",
        "    # If you want to run it directly, uncomment the line below:\n",
        "    # quick_fix(\"your_notebook.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VEnfBv1F83M",
        "outputId": "2b8037be-2522-46d8-b589-b911619e7494"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jupyter Notebook Widget Metadata Fixer\n",
            "==================================================\n",
            "🚀 HOW TO USE THIS FIX:\n",
            "==================================================\n",
            "\n",
            "METHOD 1: Fix a single notebook\n",
            "fix_notebook_widgets('your_notebook.ipynb')\n",
            "\n",
            "METHOD 2: Remove all widgets (safer)\n",
            "remove_all_widgets('your_notebook.ipynb')\n",
            "\n",
            "METHOD 3: Fix all notebooks in a directory\n",
            "batch_fix_notebooks('/path/to/your/notebooks')\n",
            "\n",
            "🔧 MANUAL ALTERNATIVE:\n",
            "1. Open your notebook in Jupyter\n",
            "2. Go to Kernel -> Restart & Clear Output\n",
            "3. Save the notebook\n",
            "4. This removes all widget states\n",
            "\n",
            "💡 PREVENTION TIPS:\n",
            "- Always clear output before committing: Cell -> All Output -> Clear\n",
            "- Use 'Restart & Clear Output' before saving\n",
            "- Add .ipynb_checkpoints/ to .gitignore\n",
            "\n",
            "🐙 GITHUB SPECIFIC:\n",
            "- GitHub renders notebooks better without widget metadata\n",
            "- Consider using nbstripout: pip install nbstripout\n",
            "- Add git filter: nbstripout --install\n",
            "\n",
            "🎯 TO FIX YOUR NOTEBOOK:\n",
            "quick_fix('your_notebook.ipynb')\n",
            "# OR\n",
            "remove_all_widgets('your_notebook.ipynb')\n"
          ]
        }
      ]
    }
  ]
}